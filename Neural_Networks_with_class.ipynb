{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Networks_with_class.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Toadoum/Machine-Learning-from-scratch/blob/main/Neural_Networks_with_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnso4Pmfvc-n"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scale(x):\n",
        "  x_scaled= (x-x.mean(0))/x.std(0)\n",
        "  return x_scaled"
      ],
      "metadata": {
        "id": "p_GOn73mTGum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Question 0: Import the dataset Dataset`"
      ],
      "metadata": {
        "id": "61r61O-4wGGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = datasets.make_regression(n_samples=1000, n_features=4, shuffle=True, coef=False, random_state=None)\n",
        "x_data = pd.DataFrame(data[0], columns = ['A', 'B', 'C', 'D'])\n",
        "y_data = pd.DataFrame(data[1], columns = ['Output'])\n",
        "\n",
        "frames = [x_data, y_data]\n",
        "data = pd.concat(frames, axis =1)"
      ],
      "metadata": {
        "id": "D1EIZ7a0v0G-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.iloc[:,-1:]= scale(data)"
      ],
      "metadata": {
        "id": "J9_FW80YTYAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data1(df, train_percent= 0.8):\n",
        "  \n",
        "  np.random.seed(2)\n",
        "  perm = np.random.permutation(df.index)\n",
        "\n",
        "  n= len(df)\n",
        "  train_index = int(train_percent * n)\n",
        "\n",
        "  train = df.iloc[perm[:train_index]]\n",
        "  test = df.iloc[perm[train_index:]]\n",
        "\n",
        "  x_train, x_test, y_train, y_test= train.iloc[:, :-1], test.iloc[:, :-1], train.iloc[:, -1], test.iloc[:, -1]\n",
        "\n",
        "  assert (x_train.shape==(int(0.8*len(data)), 4))\n",
        "  assert (x_test.shape==(200, 4))\n",
        "  assert (y_train.shape==(int(0.8*len(data)), ))\n",
        "  assert (y_test.shape==(200, ))\n",
        "  print('✅✅✅ Congratulation: Your data is is correctly splitted.')\n",
        "  print((data.shape))\n",
        "  return x_train.values, x_test.values, y_train.values, y_test.values\n",
        "\n",
        "x_train, x_test, y_train, y_test= split_data1(data, 0.8) \n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAYcV2DOTSSe",
        "outputId": "71561126-c823-44a3-f2e8-f1e99da5d7be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅✅✅ Congratulation: Your data is is correctly splitted.\n",
            "(1000, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((800, 4), (800,), (200, 4), (200,))"
            ]
          },
          "metadata": {},
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(-10, 10, 100)"
      ],
      "metadata": {
        "id": "9fwrsUkz2I2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Get dimension of layers\n",
        "input_dim= data.shape[1]-1 # number of features\n",
        "hidden_dim= 10 # number of units in the hideen layer\n",
        "output_dim= 1 # number of units in the output layer"
      ],
      "metadata": {
        "id": "Cpf9HGkV6QV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BGD\n",
        "class NN:\n",
        "  def __init__(self, x_test, y_test, size, num_epochs= 4000, lr= 0.0038, threshold= 0.5):\n",
        "    '''\n",
        "    size: a list of dimensions\n",
        "    '''\n",
        "    self.x_test=x_test\n",
        "    self.y_test=y_test\n",
        "    self.size=size\n",
        "    self.num_epochs=num_epochs\n",
        "    self.lr=lr\n",
        "    self.threshold=threshold\n",
        "    self.cost_train=[]\n",
        "    self.cost_test=[]\n",
        "    self.params=self.weight_initialization()\n",
        "\n",
        "  def sigmoid(self,x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "  \n",
        "  def dsigmoid(self,x):\n",
        "    return self.sigmoid(x)*(1- self.sigmoid(x))\n",
        "\n",
        "  def tanh(self,x):\n",
        "    t=(np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n",
        "    return t\n",
        "\n",
        "  def dtanh(self,x):\n",
        "    return 1- self.tanh(x)**2\n",
        "\n",
        "  def cross_entropy(self,y,y_pred):\n",
        "    loss= np.sum(y*np.log(y_pred)+(1-y)*np.log(1-y_pred))/len(y)\n",
        "    return loss\n",
        "\n",
        "  def mean_squared_error(self,y,y_pred):\n",
        "    loss= np.mean((y - y_pred)**2, axis =1)\n",
        "    return loss\n",
        "\n",
        "  def ReLU(x):\n",
        "    data=x * (x > 0)\n",
        "    #data = np.maximum(0,x)\n",
        "    return np.array(data, dtype=float)\n",
        "\n",
        "  # Derivative for ReLU\n",
        "  def der_ReLU(x):\n",
        "    data=1. * (x > 0)\n",
        "    return np.array(data, dtype=float)\n",
        "    \n",
        "  def weight_initialization(self):\n",
        "    input_dim= self.size[0]\n",
        "    hidden_dim= self.size[1]\n",
        "    output_dim= self.size[2]\n",
        "\n",
        "\n",
        "    params = {\n",
        "            'w1':np.random.rand(hidden_dim*input_dim).reshape(hidden_dim,input_dim)*0.01,\n",
        "            'b1':np.random.rand(hidden_dim*1).reshape(hidden_dim,1),\n",
        "            'w2':np.random.rand(output_dim*hidden_dim).reshape(output_dim,hidden_dim)*0.01,\n",
        "            'b2':np.random.rand(output_dim*1).reshape(output_dim,1) \n",
        "        }\n",
        "\n",
        "    return params\n",
        "\n",
        "  def forward_pass(self, x,b1,b2,w1, w2):\n",
        "    params= self.params\n",
        "\n",
        "    w1= params['w1']\n",
        "    b1= params['b1']\n",
        "\n",
        "    w2= params['w2']\n",
        "    b2= params['b2']\n",
        "\n",
        "    # ForwardPass\n",
        "    z1= w1 @ x.T + b1\n",
        "    a1= self.ReLU()\n",
        "\n",
        "    z2= w2@ a1+b2\n",
        "    a2= self.ReLU(z2)\n",
        "\n",
        "    assert (z1.shape==(self.size[1], x.shape[0]))\n",
        "    assert (a1.shape==(self.size[1], x.shape[0]))\n",
        "\n",
        "    assert (z2.shape==(self.size[2], x.shape[0]))\n",
        "    assert (a2.shape==(self.size[2], x.shape[0]))\n",
        "\n",
        "    print('Congratulation: Your forward is correct.')\n",
        "\n",
        "    return z1, a1, z2, a2\n",
        "  \n",
        "  def backward_pass(self, x, y, w1, b1, w2, b2):\n",
        "    params= self.params\n",
        "\n",
        "    w1= params['w1']\n",
        "    b1= params['b1']\n",
        "\n",
        "    w2= params['w2']\n",
        "    b2= params['b2']\n",
        "\n",
        "    # Backward\n",
        "\n",
        "    z1, a1, z2,a2= self.forward_pass(x, w1, b1, w2, b2)\n",
        "    N= len(x)\n",
        "\n",
        "    dw1= (((1-a1*a1)*(a2-y))*w2.T)@x\n",
        "  #print(dw1.shape)\n",
        "    db1=(((a2-y)@(1-a1*a1).T)*w2).T\n",
        "  #db1= (np.sum(((a2-y)*(1-a1*a1))*w2.T, axis=1)/len(y)).reshape(-1,1)\n",
        "  #print(db1.shape)\n",
        "\n",
        "    assert (dw1.shape== w1.shape), 'The dimension of dw1 and w1 must be the same'\n",
        "    assert (db1.shape== b1.shape), 'The dimension of db2 and b1 must be the same'\n",
        "\n",
        "\n",
        "    dw2= (a2-y)@a1.T\n",
        "    #print(dw2.shape)\n",
        "    db2= (np.sum((a2-y).flatten())/N).reshape(-1,1)\n",
        "\n",
        "    # Dimension check\n",
        "    assert (dw2.shape== w2.shape), 'The dimension of dw2 and w2 must be the same'\n",
        "    assert (db2.shape== b2.shape), 'The dimension of db2 and b2 must be the same'\n",
        "\n",
        "    print('Congratulation: Your Backward is correct.')\n",
        "\n",
        "    return dw1, db1, dw2, db2\n",
        "\n",
        "  def train(self, x, y):\n",
        "\n",
        "    for i in range(self.num_epochs):\n",
        "      for i in range(len(x)):\n",
        "        params= self.params\n",
        "\n",
        "        w1= params['w1']\n",
        "        b1= params['b1']\n",
        "\n",
        "        w2= params['w2']\n",
        "        b2= params['b2']\n",
        "\n",
        "        dw1, db1, dw2, db2 = self.backward_pass(x,y, w1, b1, w2, b2)\n",
        "\n",
        "        params['w1']= w1-self.lr*dw1\n",
        "        params['b1']=  b1-self.lr*db1\n",
        "\n",
        "        params['w2']= w2-self.lr*dw2\n",
        "        params['b2']= b2-self.lr*db2\n",
        "\n",
        "        # Get the Train Loss: forward pass and cross-entropy computatation\n",
        "        z1, a1, z2,y_pred= self.forward_pass(x)\n",
        "        c = self.mean_squared_error(y,y_pred)\n",
        "        print(c)\n",
        "        self.cost_train.append(c)\n",
        "\n",
        "        # Get the Test Loss: forward pass and cross-entropy computatation\n",
        "        z1, a1, z2,y_pred_test= self.forward_pass(x_test)\n",
        "        c_test = self.mean_squared_error(y_test,y_pred_test)\n",
        "        self.cost_test.append(c_test)\n",
        "\n",
        "  def get_class(self, x):\n",
        "    params= self.params\n",
        "\n",
        "    w1= params['w1']\n",
        "    b1= params['b1']\n",
        "\n",
        "    w2= params['w2']\n",
        "    b2= params['b2']\n",
        "    # Foward pass on x\n",
        "    _,_,_,proba= self.forward_pass(x,b1,b2,w1, w2)# Get probability of x\n",
        "    result= [1 if i > self.threshold else 0 for i in proba[0]] # Convert proba to 0 or 1. hint: list comprehension\n",
        "    return np.array(result), proba\n",
        "\n",
        "  def accuracy(self, y,y_pred):\n",
        "    return (np.sum(y_pred==y)/len(y))\n",
        "\n",
        "  def plot(self):\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Cost')\n",
        "    plt.plot(np.arange(len(self.cost_train)), self.cost_train, 'r', linewidth = \"2\", label= 'Train Loss')\n",
        "    plt.plot(np.arange(len(self.cost_test)), self.cost_test, 'b', linewidth = \"2\", label= 'Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "xACAIzEPFB_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=NN(x_test, y_test, size=[4,10,1], num_epochs= 5, lr= 0.00001, threshold= 0.5)"
      ],
      "metadata": {
        "id": "BHCsueDQQqsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(x_train,y_train)"
      ],
      "metadata": {
        "id": "XUEO31wO9V9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.plot()"
      ],
      "metadata": {
        "id": "weuFAVaa_nwg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}